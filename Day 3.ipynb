{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled34.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOvQHKbxi3y0HE3hJQ5bSGK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoaoSiqueiraDS/DS_Days/blob/October/Day%203.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsh0W-JQUaKl",
        "outputId": "9488634b-00b9-401d-ec7b-bf3543fdf320",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# a 2x2 matrix\n",
        "A = np.array([[0,1],[-2,-3]])\n",
        "\n",
        "# find eigenvalues and eigenvectors\n",
        "vals, vecs = np.linalg.eig(A)\n",
        "\n",
        "# print results\n",
        "for i, value in enumerate(vals):\n",
        "    print(\"Eigenvector:\", vecs[:,i], \", Eigenvalue:\", value)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Eigenvector: [ 0.70710678 -0.70710678] , Eigenvalue: -1.0\n",
            "Eigenvector: [-0.4472136   0.89442719] , Eigenvalue: -2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkafm4Xn7deF",
        "outputId": "38c9d637-6b2f-471e-fad0-048049c5a61c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "A = np.array([\n",
        "  [0, 1, 1, 0, 0, 0, 0, 0, 1, 1],\n",
        "  [1, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
        "  [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "  [0, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
        "  [0, 0, 0, 1, 0, 1, 0, 0, 0, 0],\n",
        "  [0, 0, 0, 1, 1, 0, 1, 1, 0, 0],\n",
        "  [0, 0, 0, 0, 0, 1, 0, 1, 0, 0],\n",
        "  [0, 0, 0, 0, 0, 1, 1, 0, 0, 0],\n",
        "  [1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
        "  [1, 0, 0, 0, 0, 0, 0, 0, 1, 0]])\n",
        "\n",
        "# our adjacency matrix\n",
        "print(\"Adjacency Matrix:\")\n",
        "print(A)\n",
        "\n",
        "# Adjacency Matrix:\n",
        "# [[0. 1. 1. 0. 0. 1. 0. 0. 1. 1.]\n",
        "#  [1. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
        "#  [1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
        "#  [0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]\n",
        "#  [0. 0. 0. 1. 0. 1. 0. 0. 0. 0.]\n",
        "#  [1. 0. 0. 1. 1. 0. 1. 1. 0. 0.]\n",
        "#  [0. 0. 0. 0. 0. 1. 0. 1. 0. 0.]\n",
        "#  [0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
        "#  [1. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
        "#  [1. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n",
        "\n",
        "# diagonal matrix\n",
        "D = np.diag(A.sum(axis=1))\n",
        "\n",
        "# graph laplacian\n",
        "L = D-A\n",
        "\n",
        "# eigenvalues and eigenvectors\n",
        "vals, vecs = np.linalg.eig(L)\n",
        "\n",
        "# sort these based on the eigenvalues\n",
        "vecs = vecs[:,np.argsort(vals)]\n",
        "vals = vals[np.argsort(vals)]\n",
        "\n",
        "# kmeans on first three vectors with nonzero eigenvalues\n",
        "kmeans = KMeans(n_clusters=4)\n",
        "kmeans.fit(vecs[:,1:4])\n",
        "colors = kmeans.labels_\n",
        "\n",
        "print(\"Clusters:\", colors)\n",
        "\n",
        "# Clusters: [2 1 1 0 0 0 3 3 2 2]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Adjacency Matrix:\n",
            "[[0 1 1 0 0 0 0 0 1 1]\n",
            " [1 0 1 0 0 0 0 0 0 0]\n",
            " [1 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 1 0 0 0 0]\n",
            " [0 0 0 1 0 1 0 0 0 0]\n",
            " [0 0 0 1 1 0 1 1 0 0]\n",
            " [0 0 0 0 0 1 0 1 0 0]\n",
            " [0 0 0 0 0 1 1 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 1]\n",
            " [1 0 0 0 0 0 0 0 1 0]]\n",
            "Clusters: [2 0 0 1 1 3 3 3 2 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2s9QRo5UBxOb"
      },
      "source": [
        "The code above is a demonstrations of spectral clustering. It involves lots of math (such as eigenvalues e eigenvectors). It is a important part of machine learning and worth studying. Even though I haven't completelly understood everything, it was a nice intro into machine learning stuff. Following it is a summary of spectral clustering from the author ... By the way, that's the link to the Medium TDS article - (https://towardsdatascience.com/spectral-clustering-aba2640c0d5b). \n",
        "\n",
        "\n",
        "\"To summarize, we first took our graph and built an adjacency matrix. We then created the Graph Laplacian by subtracting the adjacency matrix from the degree matrix. The eigenvalues of the Laplacian indicated that there were four clusters. The vectors associated with those eigenvalues contain information on how to segment the nodes. Finally, we performed K-Means on those vectors in order to get the labels for the nodes. Next, weâ€™ll see how to do this for arbitrary data.\""
      ]
    }
  ]
}